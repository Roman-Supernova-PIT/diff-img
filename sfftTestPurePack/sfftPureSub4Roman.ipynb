{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Image Subtraction on Roman observations with SFFT \n",
    "\n",
    "Author: Lei Hu <leihu@andrew.cmu.edu>  \n",
    "Last Verified to run: 2024-09-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup directory paths\n",
    "# TODO: change MAINDIR to your own directory!\n",
    "MAINDIR = '/hildafs/projects/phy220048p/leihu/AstroWork/DECamDIA/notebooks/snpit/sfftTestPurePack'\n",
    "input_dir = MAINDIR + '/input'\n",
    "output_dir = MAINDIR + '/output'\n",
    "aux_dir = MAINDIR + '/auxiliary'\n",
    "utils_dir = MAINDIR + '/utils'\n",
    "\n",
    "# setup reference & science filename\n",
    "refname = 'Roman_WAS_simple_model_H158_9758_15'\n",
    "sciname = 'Roman_WAS_simple_model_H158_11832_15'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1. resampling [science image & detection mask onto reference frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeLOn CheckPoint: Cuda resampling takes [0.000050 s]\n",
      "MeLOn CheckPoint: resampled fits file saved at \n",
      " # [/hildafs/projects/phy220048p/leihu/AstroWork/DECamDIA/notebooks/snpit/sfftTestPurePack/output/Roman_WAS_simple_model_H158_11832_15.sciE.skysub.resamp.fits]\n",
      "MeLOn CheckPoint: Cuda resampling takes [0.000020 s]\n",
      "MeLOn CheckPoint: resampled fits file saved at \n",
      " # [/hildafs/projects/phy220048p/leihu/AstroWork/DECamDIA/notebooks/snpit/sfftTestPurePack/output/Roman_WAS_simple_model_H158_11832_15.sciE.skysub.detmask.resamp.fits]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os.path as pa\n",
    "sys.path.insert(1, utils_dir)\n",
    "from CudaResampling import Cuda_Resampling\n",
    "\n",
    "FITS_REF = input_dir + \"/%s.sciE.skysub.fits\" % refname\n",
    "FITS_oSCI = input_dir + \"/%s.sciE.skysub.fits\" % sciname\n",
    "\n",
    "FITS_REF_DMASK = input_dir + \"/%s.sciE.skysub.detmask.fits\" % refname\n",
    "FITS_oSCI_DMASK = input_dir + \"/%s.sciE.skysub.detmask.fits\" % sciname\n",
    "\n",
    "assert pa.exists(FITS_REF) and pa.exists(FITS_oSCI) \n",
    "assert pa.exists(FITS_REF_DMASK) and pa.exists(FITS_oSCI_DMASK)\n",
    "\n",
    "FITS_SCI = output_dir + \"/%s.sciE.skysub.resamp.fits\" % sciname\n",
    "FITS_SCI_DMASK = output_dir + \"/%s.sciE.skysub.detmask.resamp.fits\" % sciname\n",
    "\n",
    "# run resampling using CUDA code\n",
    "Cuda_Resampling.CR(FITS_obj=FITS_oSCI, FITS_targ=FITS_REF, FITS_resamp=FITS_SCI, \n",
    "    METHOD='BILINEAR', FILL_ZEROPIX=True, VERBOSE_LEVEL=1)\n",
    "Cuda_Resampling.CR(FITS_obj=FITS_oSCI_DMASK, FITS_targ=FITS_REF_DMASK, FITS_resamp=FITS_SCI_DMASK, \n",
    "    METHOD='BILINEAR', FILL_ZEROPIX=False, VERBOSE_LEVEL=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2. extract psf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring visit and sca from image_name.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hildafs/home/leihu/.conda/envs/envR/lib/python3.10/site-packages/erfa/core.py:154: ErfaWarning: ERFA function \"d2dtf\" yielded 1 of \"dubious year (Note 5)\"\n",
      "  warnings.warn('ERFA function \"{}\" yielded {}'.format(func_name, wmsg),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring visit and sca from image_name.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hildafs/home/leihu/.conda/envs/envR/lib/python3.10/site-packages/erfa/core.py:154: ErfaWarning: ERFA function \"d2dtf\" yielded 1 of \"dubious year (Note 5)\"\n",
      "  warnings.warn('ERFA function \"{}\" yielded {}'.format(func_name, wmsg),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeLOn CheckPoint: NO IMAGE ZOOM!\n",
      "MeLOn CheckPoint: Modify WCS to adapt to the Rotated Frame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1M> \n",
      "\u001b[1A----- SWarp 2.38.0 started on 2024-09-11 at 10:44:47 with 256 threads\n",
      "\n",
      "\u001b[1M> Examining input data ...\n",
      "\u001b[1A\u001b[1M> Looking for original_image.fits ...\n",
      "\u001b[1A\u001b[1M> Creating NEW output image ...\n",
      "\u001b[1A\n",
      "> WARNING: FITS header data read in /tmp/PYSWarp_e4ua7fhy/original_image.tmp_resamp.head\n",
      "\n",
      "\u001b[1M> Creating NEW weight-map ...\n",
      "\u001b[1A\u001b[1M> \n",
      "\u001b[1A------- Output File original_image.tmp_resamp.fits:\n",
      "    \"no ident\"  WEIGHTED  EXT. HEADER  501x501  32 bits (floats)\n",
      "    Center: 12:00:00.00 +00:00:00.0   8.35'x8.35'  Scale: 1 ''/pixel\n",
      "    Gain: 0 e-/ADU   Flux scaling (astrom/photom): 1 X / 1 X\n",
      "\n",
      "\u001b[1M> Loading input data ...\n",
      "\u001b[1A\u001b[1M> \n",
      "\u001b[1A-------------- File original_image.fits:\n",
      "    \"no ident\"  unweighted  no ext. header  501x501  32 bits (floats)\n",
      "    Center: 12:00:00.00 +00:00:00.0   8.35'x8.35'  Scale: 1 ''/pixel\n",
      "    Gain: 1 e-/ADU   Flux scaling (astrom/photom): 1 X / 1 X\n",
      "\u001b[1M> Setting up background maps ...\n",
      "\u001b[1A\u001b[1M> Filtering background map(s) ...\n",
      "\u001b[1A\u001b[1M> Computing backgound d-map ...\n",
      "\u001b[1A\u001b[1M> Computing backgound-noise d-map ...\n",
      "\u001b[1A    Background: 4.088268e-11   RMS: 7.381394e-10\n",
      "\n",
      "\u001b[1M> Reading /tmp/tmpmc0_ck8q/original_image.fits\n",
      "\u001b[1A\u001b[1M> Resampling /tmp/tmpmc0_ck8q/original_image.fits ...\n",
      "\u001b[1A\u001b[1M> Resampling line:      0 / 501    \n",
      "\u001b[1A-------------- Co-adding frames            \n",
      "Maximum overlap density: 1 frame\n",
      "\u001b[1M> Preparing line:      1 / 501    \n",
      "\u001b[1A\u001b[1M> Reading   line:      1 / 501    \n",
      "\u001b[1A\u001b[1M> Co-adding line:      1 / 501    \n",
      "\u001b[1A\u001b[1M> Writing   line:      1 / 501    \n",
      "\u001b[1A\u001b[1M> Closing files ...\n",
      "\u001b[1A\u001b[1M> \n",
      "\u001b[1A> All done (in 0.2 s)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import galsim\n",
    "import numpy as np\n",
    "import os.path as pa\n",
    "from astropy.io import fits\n",
    "from sfft.utils.ReadWCS import Read_WCS\n",
    "from ImageZoomRotate import Image_ZoomRotate\n",
    "from roman_imsim.utils import roman_utils\n",
    "\n",
    "# TODO: change aux_dir PATH in your was.yaml file!\n",
    "config_file = aux_dir + '/was.yaml'\n",
    "assert pa.exists(config_file)\n",
    "\n",
    "# retrieve psf model at reference image center\n",
    "util_ref = roman_utils(config_file=config_file, image_name='%s.fits' %refname)\n",
    "psf_image_ref = util_ref.getPSF_Image(501, x=2048.5, y=2048.5).array\n",
    "\n",
    "FITS_PSF_REF = output_dir + '/%s.centPSF.fits' %refname\n",
    "fits.HDUList([fits.PrimaryHDU(data=psf_image_ref, header=None)]).writeto(FITS_PSF_REF, overwrite=True)\n",
    "\n",
    "# retrieve psf model at (unresampled) science image center\n",
    "util_sci = roman_utils(config_file=config_file, image_name='%s.fits' %sciname)\n",
    "psf_image_sci = util_ref.getPSF_Image(501, x=2048.5, y=2048.5).array\n",
    "\n",
    "FITS_PSF_SCI = output_dir + '/%s.centPSF.fits' %sciname\n",
    "fits.HDUList([fits.PrimaryHDU(data=psf_image_sci, header=None)]).writeto(FITS_PSF_SCI, overwrite=True)\n",
    "\n",
    "# rotate PSF model to align resampled image\n",
    "def calculate_skyN_vector(wcshdr, x_start, y_start, shift_dec=1.0):\n",
    "    w = Read_WCS.RW(wcshdr, VERBOSE_LEVEL=1)\n",
    "    ra_start, dec_start = w.all_pix2world(np.array([[x_start, y_start]]), 1)[0]\n",
    "    ra_end, dec_end = ra_start, dec_start + shift_dec/3600.0\n",
    "    x_end, y_end = w.all_world2pix(np.array([[ra_end, dec_end]]), 1)[0]\n",
    "    skyN_vector = np.array([x_end - x_start, y_end - y_start])\n",
    "    return skyN_vector\n",
    "\n",
    "def calculate_rotate_angle(vector_ref, vector_obj):\n",
    "    rad = np.arctan2(np.cross(vector_ref, vector_obj), np.dot(vector_ref, vector_obj))\n",
    "    rotate_angle = np.rad2deg(rad)\n",
    "    if rotate_angle < 0.0: rotate_angle += 360.0 \n",
    "    return rotate_angle\n",
    "\n",
    "# calculate rotation angle during resampling\n",
    "_phdr = fits.getheader(FITS_oSCI, ext=0)\n",
    "_w = Read_WCS.RW(_phdr, VERBOSE_LEVEL=1)\n",
    "x0, y0 = 0.5 + int(_phdr['NAXIS1'])/2.0, 0.5 + int(_phdr['NAXIS2'])/2.0\n",
    "ra0, dec0 = _w.all_pix2world(np.array([[x0, y0]]), 1)[0]\n",
    "skyN_vector = calculate_skyN_vector(wcshdr=_phdr, x_start=x0, y_start=y0)\n",
    "\n",
    "_phdr = fits.getheader(FITS_SCI, ext=0)\n",
    "_w = Read_WCS.RW(_phdr, VERBOSE_LEVEL=1)\n",
    "x1, y1 = _w.all_world2pix(np.array([[ra0, dec0]]), 1)[0]\n",
    "skyN_vectorp = calculate_skyN_vector(wcshdr=_phdr, x_start=x1, y_start=y1)\n",
    "PATTERN_ROTATE_ANGLE = calculate_rotate_angle(vector_ref=skyN_vector, vector_obj=skyN_vectorp)\n",
    "\n",
    "# perform rotation to get rotated psf model for resampled science\n",
    "FITS_PSF_SCI = output_dir + '/%s.centPSF.fits' %sciname\n",
    "PixA_PSF_SCI = fits.getdata(FITS_PSF_SCI, ext=0).T\n",
    "PSF_PSF_ReSCI = Image_ZoomRotate.IZR(PixA_obj=PixA_PSF_SCI, ZOOM_SCALE_X=1., \\\n",
    "    ZOOM_SCALE_Y=1., PATTERN_ROTATE_ANGLE=PATTERN_ROTATE_ANGLE, \\\n",
    "    RESAMPLING_TYPE='BILINEAR', FILL_VALUE=0.0, VERBOSE_LEVEL=1)[0]\n",
    "\n",
    "FITS_PSF_ReSCI = output_dir + '/%s.resamp.centPSF.fits' %sciname\n",
    "fits.HDUList([fits.PrimaryHDU(data=PSF_PSF_ReSCI.T, header=None)]).writeto(FITS_PSF_ReSCI, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3. cross convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MeLOn CheckPoint: Convolving image ... \n",
      " # /hildafs/projects/phy220048p/leihu/AstroWork/DECamDIA/notebooks/snpit/sfftTestPurePack/output/Roman_WAS_simple_model_H158_9758_15.sciE.skysub.crossConvd.fits!\n",
      "\n",
      "MeLOn CheckPoint: Convolving image ... \n",
      " # /hildafs/projects/phy220048p/leihu/AstroWork/DECamDIA/notebooks/snpit/sfftTestPurePack/output/Roman_WAS_simple_model_H158_11832_15.sciE.skysub.resamp.crossConvd.fits!\n"
     ]
    }
   ],
   "source": [
    "from astropy.convolution import convolve_fft\n",
    "\n",
    "FITS_lREF = input_dir + '/%s.sciE.skysub.fits' % refname\n",
    "FITS_lSCI = output_dir + '/%s.sciE.skysub.resamp.fits' % sciname\n",
    "\n",
    "FITS_PSF_lREF = output_dir + '/%s.centPSF.fits' % refname\n",
    "FITS_PSF_lSCI = output_dir + '/%s.resamp.centPSF.fits' % sciname\n",
    "\n",
    "FITS_lREF_convd = output_dir + '/%s.sciE.skysub.crossConvd.fits' % refname\n",
    "FITS_lSCI_convd = output_dir + '/%s.sciE.skysub.resamp.crossConvd.fits' % sciname\n",
    "\n",
    "PixA_lREF = fits.getdata(FITS_lREF, ext=0).T\n",
    "PixA_lSCI = fits.getdata(FITS_lSCI, ext=0).T\n",
    "\n",
    "PixA_PSF_lREF = fits.getdata(FITS_PSF_lREF, ext=0).T\n",
    "PixA_PSF_lSCI = fits.getdata(FITS_PSF_lSCI, ext=0).T\n",
    "\n",
    "# convolve (resampled) science psf on reference\n",
    "PixA_lREF_convd = convolve_fft(PixA_lREF, PixA_PSF_lSCI, boundary='fill', \\\n",
    "    nan_treatment='fill', fill_value=0.0, normalize_kernel=True)\n",
    "\n",
    "if FITS_lREF_convd is not None:\n",
    "    with fits.open(FITS_lREF) as hdl:\n",
    "        _message = 'Convolving image ... \\n # %s' %FITS_lREF_convd\n",
    "        print('\\nMeLOn CheckPoint: %s!' %_message)\n",
    "        hdl[0].data[:, :] = PixA_lREF_convd.T\n",
    "        hdl.writeto(FITS_lREF_convd, overwrite=True)\n",
    "    \n",
    "# convolve reference psf on (resampled) science\n",
    "PixA_lSCI_convd = convolve_fft(PixA_lSCI, PixA_PSF_lREF, boundary='fill', \\\n",
    "    nan_treatment='fill', fill_value=0.0, normalize_kernel=True)\n",
    "\n",
    "if FITS_lSCI_convd is not None:\n",
    "    with fits.open(FITS_lSCI) as hdl:\n",
    "        _message = 'Convolving image ... \\n # %s' %FITS_lSCI_convd\n",
    "        print('\\nMeLOn CheckPoint: %s!' %_message)\n",
    "        hdl[0].data[:, :] = PixA_lSCI_convd.T\n",
    "        hdl.writeto(FITS_lSCI_convd, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 4: make cutous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfft.utils.StampGenerator import Stamp_Generator\n",
    "\n",
    "# make a cutout for subtraction test\n",
    "FITS_lREF = input_dir + '/%s.sciE.skysub.fits' % refname\n",
    "FITS_lSCI = output_dir + '/%s.sciE.skysub.resamp.fits' % sciname\n",
    "\n",
    "FITS_lREF_DMASK = input_dir + \"/%s.sciE.skysub.detmask.fits\" % refname\n",
    "FITS_lSCI_DMASK = output_dir + \"/%s.sciE.skysub.detmask.resamp.fits\" % sciname\n",
    "\n",
    "FITS_lREF_convd = output_dir + '/%s.sciE.skysub.crossConvd.fits' % refname\n",
    "FITS_lSCI_convd = output_dir + '/%s.sciE.skysub.resamp.crossConvd.fits' % sciname\n",
    "\n",
    "STAMP_IMGSIZE = (1024, 1024) # stamp image size\n",
    "COORD = np.array([[1195.5299, 2972.6193]])  # image coordinate\n",
    "\n",
    "for FITS_obj in [FITS_lREF, FITS_lSCI, FITS_lREF_DMASK, FITS_lSCI_DMASK, FITS_lREF_convd, FITS_lSCI_convd]:\n",
    "    FITS_StpLst = [output_dir + \"/%s.stamp.fits\" % (pa.basename(FITS_obj)[:-5])]\n",
    "    Stamp_Generator.SG(FITS_obj=FITS_obj, COORD=COORD, COORD_TYPE='IMAGE', \\\n",
    "        STAMP_IMGSIZE=STAMP_IMGSIZE, FILL_VALUE=np.nan, FITS_StpLst=FITS_StpLst, VERBOSE_LEVEL=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5. image subtraction using sfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeLOn CheckPoint: TRIGGER Function Compilations of SFFT-SUBTRACTION!\n",
      "\n",
      " --//--//--//--//-- TRIGGER SFFT COMPILATION --//--//--//--//-- \n",
      "\n",
      " ---//--- KerPolyOrder 3 | BGPolyOrder 0 | KerHW [9] ---//--- \n",
      "\n",
      " --//--//--//--//-- EXIT SFFT COMPILATION --//--//--//--//-- \n",
      "\n",
      "MeLOn Report: Function Compilations of SFFT-SUBTRACTION TAKES [0.000 s]\n",
      "MeLOn CheckPoint: TRIGGER SFFT-SUBTRACTION!\n",
      "\n",
      "                                __    __    __    __\n",
      "                               /  \\  /  \\  /  \\  /  \\\n",
      "                              /    \\/    \\/    \\/    \\\n",
      "            █████████████████/  /██/  /██/  /██/  /█████████████████████████\n",
      "                            /  / \\   / \\   / \\   / \\  \\____\n",
      "                           /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "                          / _/                       \\_____/  `\n",
      "                          |/\n",
      "        \n",
      "                      █████████  ███████████ ███████████ ███████████        \n",
      "                     ███░░░░░███░░███░░░░░░█░░███░░░░░░█░█░░░███░░░█            \n",
      "                    ░███    ░░░  ░███   █ ░  ░███   █ ░ ░   ░███  ░ \n",
      "                    ░░█████████  ░███████    ░███████       ░███    \n",
      "                     ░░░░░░░░███ ░███░░░█    ░███░░░█       ░███    \n",
      "                     ███    ░███ ░███  ░     ░███  ░        ░███    \n",
      "                    ░░█████████  █████       █████          █████   \n",
      "                     ░░░░░░░░░  ░░░░░       ░░░░░          ░░░░░         \n",
      "        \n",
      "                    Saccadic Fast Fourier Transform (SFFT) algorithm\n",
      "                    sfft (v1.*) supported by @LeiHu\n",
      "        \n",
      "                    GitHub: https://github.com/thomasvrussell/sfft\n",
      "                    Related Paper: https://arxiv.org/abs/2109.09334\n",
      "                    \n",
      "            ████████████████████████████████████████████████████████████████\n",
      "            \n",
      "            \n",
      "\n",
      " --||--||--||--||-- TRIGGER SFFT SUBTRACTION --||--||--||--||-- \n",
      "\n",
      " ---||--- KerPolyOrder 3 | BGPolyOrder 0 | KerHW [9] ---||--- \n",
      "\n",
      "MeLOn CheckPoint: SFFT-SUBTRACTION Preliminary Steps takes [9.0095s]\n",
      "/////   a   ///// Read Input Images  (0.0075s)\n",
      "/////   b   ///// Spatial Polynomial (0.0841s)\n",
      "/////   c   ///// DFT-12             (8.9146s)\n",
      "\n",
      "MeLOn CheckPoint: SFFT-SUBTRACTION Establish & Solve Linear System takes [20.9951s]\n",
      "/////   d   ///// Establish OMG                       (0.2117s)\n",
      "/////   e   ///// Establish GAM                       (0.0375s)\n",
      "/////   f   ///// Establish PSI                       (0.0789s)\n",
      "/////   g   ///// Establish PHI                       (0.1275s)\n",
      "/////   h   ///// Establish THE & DEL                 (0.0941s)\n",
      "/////   i   ///// Solve Linear System                 (20.3554s)\n",
      "\n",
      " --||--||--||--||-- EXIT SFFT SUBTRACTION --||--||--||--||-- \n",
      "\n",
      " --||--||--||--||-- TRIGGER SFFT SUBTRACTION --||--||--||--||-- \n",
      "\n",
      " ---||--- KerPolyOrder 3 | BGPolyOrder 0 | KerHW [9] ---||--- \n",
      "\n",
      "MeLOn CheckPoint: SFFT-SUBTRACTION Preliminary Steps takes [0.0120s]\n",
      "/////   a   ///// Read Input Images  (0.0081s)\n",
      "/////   b   ///// Spatial Polynomial (0.0001s)\n",
      "/////   c   ///// DFT-12             (0.0010s)\n",
      "\n",
      "MeLOn CheckPoint: SFFT-SUBTRACTION Perform Subtraction takes [0.1986s]\n",
      "/////   j   ///// Calculate Kab         (0.1207s)\n",
      "/////   k   ///// Construct DIFF        (0.0779s)\n",
      "\n",
      " --||--||--||--||-- EXIT SFFT SUBTRACTION --||--||--||--||-- \n",
      "\n",
      "MeLOn Report: SFFT-SUBTRACTION TAKES [30.430 s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import os.path as pa\n",
    "from astropy.io import fits\n",
    "from tempfile import mkdtemp\n",
    "from sfft.CustomizedPacket import Customized_Packet\n",
    "\n",
    "FITS_lR = output_dir + '/%s.sciE.skysub.stamp.fits' % refname                   # use stamp\n",
    "FITS_lS = output_dir + '/%s.sciE.skysub.resamp.stamp.fits' % sciname            # use stamp\n",
    "\n",
    "FITS_dR = output_dir + '/%s.sciE.skysub.detmask.stamp.fits'  %refname           # use stamp\n",
    "FITS_dS = output_dir + '/%s.sciE.skysub.detmask.resamp.stamp.fits'  %sciname    # use stamp\n",
    "\n",
    "FITS_R = output_dir + '/%s.sciE.skysub.crossConvd.stamp.fits'  %refname         # use stamp\n",
    "FITS_S = output_dir + '/%s.sciE.skysub.resamp.crossConvd.stamp.fits'  %sciname  # use stamp\n",
    "\n",
    "PixA_dR = fits.getdata(FITS_dR, ext=0).T\n",
    "PixA_dS = fits.getdata(FITS_dS, ext=0).T\n",
    "\n",
    "LYMASK_BKG = np.logical_or(PixA_dR == 0, PixA_dS < 0.1)   # background-mask\n",
    "LYMASK_RDET = ~LYMASK_BKG\n",
    "\n",
    "FITS_DIFF = FITS_S[:-5] + '.polysfftdiff.fits'\n",
    "FITS_Solution = FITS_S[:-5] + '.polysfftsolution.fits'\n",
    "FITS_DCDIFF = FITS_S[:-5] + '.polysfftdiff.DeCorrelated.fits'\n",
    "\n",
    "# zero-out background to create masked image pair \n",
    "TDIR = mkdtemp(suffix=None, prefix='mask', dir=None)\n",
    "FITS_mREF = TDIR + '%s.masked.fits' %(pa.basename(FITS_R)[:-5])\n",
    "FITS_mSCI = TDIR + '%s.masked.fits' %(pa.basename(FITS_S)[:-5])\n",
    "\n",
    "with fits.open(FITS_R) as hdl:\n",
    "    _PixA = hdl[0].data.T\n",
    "    _PixA[LYMASK_BKG] = 0.0\n",
    "    hdl[0].data[:, :] = _PixA.T\n",
    "    hdl.writeto(FITS_mREF, overwrite=True)\n",
    "\n",
    "with fits.open(FITS_S) as hdl:\n",
    "    _PixA = hdl[0].data.T\n",
    "    _PixA[LYMASK_BKG] = 0.0\n",
    "    hdl[0].data[:, :] = _PixA.T\n",
    "    hdl.writeto(FITS_mSCI, overwrite=True)\n",
    "\n",
    "# configuration for sfft subtraction\n",
    "ForceConv = 'REF'       # convolve which side, 'SCI' or 'REF'\n",
    "GKerHW = 9\n",
    "KerPolyOrder = 3        # polynomial degree for matching kerenl spatial variation \n",
    "BGPolyOrder = 0         # polynomial degree for differential background variation, trivial here\n",
    "ConstPhotRatio = True   # constant flux scaling?\n",
    "\n",
    "BACKEND_4SUBTRACT = 'Cupy'      # FIXME: Please use 'Numpy' if no gpu device avaiable\n",
    "CUDA_DEVICE_4SUBTRACT = '0'     # gpu device index, only for Cupy backend\n",
    "NUM_CPU_THREADS_4SUBTRACT = 8   # number of cpu threads, only for Numpy backend\n",
    "\n",
    "# run polynomial form sfft subtraction \n",
    "Customized_Packet.CP(FITS_REF=FITS_R, FITS_SCI=FITS_S, FITS_mREF=FITS_mREF, FITS_mSCI=FITS_mSCI, \\\n",
    "    ForceConv=ForceConv, GKerHW=GKerHW, FITS_DIFF=FITS_DIFF, FITS_Solution=FITS_Solution, \\\n",
    "    KerPolyOrder=KerPolyOrder, BGPolyOrder=BGPolyOrder, ConstPhotRatio=ConstPhotRatio, \\\n",
    "    BACKEND_4SUBTRACT=BACKEND_4SUBTRACT, CUDA_DEVICE_4SUBTRACT=CUDA_DEVICE_4SUBTRACT, \\\n",
    "    NUM_CPU_THREADS_4SUBTRACT=NUM_CPU_THREADS_4SUBTRACT)\n",
    "os.system('rm -rf %s' %TDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5. noise decorrelation & SNR estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeLOn CheckPoint: DeCorrelation Kernel with size [1003, 1003]\n",
      "MeLOn CheckPoint: Tail-Truncation Lost-Weight [0.0000 %] (Absolute Percentage Error) \n"
     ]
    }
   ],
   "source": [
    "from sfft.utils.SkyLevelEstimator import SkyLevel_Estimator\n",
    "from sfft.utils.SFFTSolutionReader import Realize_MatchingKernel\n",
    "from sfft.utils.DeCorrelationCalculator import DeCorrelation_Calculator\n",
    "\n",
    "# run noise decorrelation for polynomial form sfft subtraction \n",
    "PixA_PSF_lREF = fits.getdata(FITS_PSF_lREF, ext=0).T\n",
    "PixA_PSF_lSCI = fits.getdata(FITS_PSF_lSCI, ext=0).T\n",
    "\n",
    "PixA_lR = fits.getdata(FITS_lR, ext=0).T # use stamp\n",
    "PixA_lS = fits.getdata(FITS_lS, ext=0).T # use stamp\n",
    "PixA_DIFF = fits.getdata(FITS_DIFF, ext=0).T \n",
    "\n",
    "bkgsig_REF = SkyLevel_Estimator.SLE(PixA_obj=PixA_lR)[1]\n",
    "bkgsig_SCI = SkyLevel_Estimator.SLE(PixA_obj=PixA_lS)[1]\n",
    "\n",
    "N0, N1 = PixA_lS.shape\n",
    "XY_q = np.array([[N0/2.+0.5, N1/2.+0.5]])\n",
    "MKerStack = Realize_MatchingKernel(XY_q).FromFITS(FITS_Solution=FITS_Solution)\n",
    "MK_Fin = MKerStack[0]\n",
    "\n",
    "DCKer = DeCorrelation_Calculator.DCC(MK_JLst=[PixA_PSF_lREF], SkySig_JLst=[bkgsig_SCI], \\\n",
    "    MK_ILst=[PixA_PSF_lSCI], SkySig_ILst=[bkgsig_REF], MK_Fin=MK_Fin, \\\n",
    "    KERatio=2.0, VERBOSE_LEVEL=2)\n",
    "\n",
    "PixA_DCDIFF = convolve_fft(PixA_DIFF, DCKer, boundary='fill', \\\n",
    "    nan_treatment='fill', fill_value=0.0, normalize_kernel=True)\n",
    "\n",
    "with fits.open(FITS_DIFF) as hdl:\n",
    "    hdl[0].data[:, :] = PixA_DCDIFF.T\n",
    "    hdl.writeto(FITS_DCDIFF, overwrite=True)\n",
    "\n",
    "# roughly estimate the SNR map for the decorrelated difference image\n",
    "# WARNING: the noise propagation is highly simplified.\n",
    "\n",
    "GAIN = 1.0  \n",
    "PixA_varREF = np.clip(PixA_lR/GAIN, a_min=0.0, a_max=None) + bkgsig_REF**2\n",
    "PixA_varSCI = np.clip(PixA_lS/GAIN, a_min=0.0, a_max=None) + bkgsig_SCI**2\n",
    "PixA_DIFF_Noise = np.sqrt(PixA_varREF + PixA_varSCI)\n",
    "\n",
    "FITS_DSNR = FITS_DIFF[:-5] + '.DeCorrelated.SNR.fits'\n",
    "PixA_DSNR = PixA_DCDIFF / PixA_DIFF_Noise\n",
    "with fits.open(FITS_DIFF) as hdl:\n",
    "    hdl[0].data[:, :] = PixA_DSNR.T\n",
    "    hdl.writeto(FITS_DSNR, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonEnvR",
   "language": "python",
   "name": "envr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
